2020-05-26 12:48:20.600 parsl.dataflow.dflow:83 [DEBUG]  Starting DataFlowKernel with config
Config(
    app_cache=True, 
    checkpoint_files=None, 
    checkpoint_mode=None, 
    checkpoint_period=None, 
    data_management_max_threads=10, 
    executors=[HighThroughputExecutor(
        address='127.0.0.1', 
        cores_per_worker=1, 
        heartbeat_period=30, 
        heartbeat_threshold=120, 
        interchange_port_range=(55000, 56000), 
        label='htex_Local', 
        launch_cmd='process_worker_pool.py {debug} {max_workers} -p {prefetch_capacity} -c {cores_per_worker} -m {mem_per_worker} --poll {poll_period} --task_url={task_url} --result_url={result_url} --logdir={logdir} --block_id={{block_id}} --hb_period={heartbeat_period} --hb_threshold={heartbeat_threshold} ', 
        managed=True, 
        max_workers=3, 
        mem_per_worker=None, 
        poll_period=10, 
        prefetch_capacity=0, 
        provider=LocalProvider(
            channel=LocalChannel(
                envs={}, 
                script_dir=None, 
                userhome='/home/aymen/SummerRadical/Parsl-RP/local-test/Parsl/src'
            ), 
            cmd_timeout=30, 
            init_blocks=1, 
            launcher=SingleNodeLauncher(), 
            max_blocks=3, 
            min_blocks=0, 
            move_files=None, 
            nodes_per_block=1, 
            parallelism=3, 
            walltime='00:15:00', 
            worker_init=''
        ), 
        storage_access=None, 
        suppress_failure=True, 
        worker_debug=True, 
        worker_logdir_root=None, 
        worker_port_range=(54000, 55000), 
        worker_ports=None, 
        working_dir=None
    )], 
    initialize_logging=True, 
    lazy_errors=True, 
    max_idletime=120.0, 
    monitoring=None, 
    retries=0, 
    run_dir='runinfo', 
    strategy=None, 
    usage_tracking=False
)
2020-05-26 12:48:20.600 parsl.dataflow.dflow:84 [INFO]  Parsl version: 0.9.0
2020-05-26 12:48:20.600 parsl.dataflow.usage_tracking.usage:126 [DEBUG]  Tracking status: False
2020-05-26 12:48:20.600 parsl.dataflow.usage_tracking.usage:127 [DEBUG]  Testing mode   : False
2020-05-26 12:48:20.600 parsl.dataflow.dflow:110 [INFO]  Run id is: f091f251-6b44-4c5a-b9a3-bcb52eb46306
2020-05-26 12:48:20.655 parsl.dataflow.memoization:52 [INFO]  App caching initialized
2020-05-26 12:48:20.656 parsl.executors.high_throughput.executor:453 [DEBUG]  Starting queue management thread
2020-05-26 12:48:20.656 parsl.executors.high_throughput.executor:326 [DEBUG]  [MTHREAD] queue management worker starting
2020-05-26 12:48:20.656 parsl.executors.high_throughput.executor:457 [DEBUG]  Started queue management thread
2020-05-26 12:48:20.683 parsl.executors.high_throughput.executor:289 [DEBUG]  Created management thread: <Thread(HTEX-Queue-Management-Thread, started daemon 139941948221184)>
2020-05-26 12:48:20.683 parsl.executors.high_throughput.executor:263 [DEBUG]  Launch command: process_worker_pool.py --debug --max_workers=3 -p 0 -c 1 -m None --poll 10 --task_url=tcp://127.0.0.1:54133 --result_url=tcp://127.0.0.1:54600 --logdir=/home/aymen/SummerRadical/Parsl-RP/local-test/Parsl/src/runinfo/000/htex_Local --block_id={block_id} --hb_period=30 --hb_threshold=120 
2020-05-26 12:48:20.683 parsl.executors.high_throughput.executor:266 [DEBUG]  Starting HighThroughputExecutor with provider:
LocalProvider(
    channel=LocalChannel(
        envs={}, 
        script_dir='/home/aymen/SummerRadical/Parsl-RP/local-test/Parsl/src/runinfo/000/submit_scripts', 
        userhome='/home/aymen/SummerRadical/Parsl-RP/local-test/Parsl/src'
    ), 
    cmd_timeout=30, 
    init_blocks=1, 
    launcher=SingleNodeLauncher(), 
    max_blocks=3, 
    min_blocks=0, 
    move_files=None, 
    nodes_per_block=1, 
    parallelism=3, 
    walltime='00:15:00', 
    worker_init=''
)
2020-05-26 12:48:20.690 parsl.executors.high_throughput.executor:569 [DEBUG]  Launched block 0->9536
2020-05-26 12:48:20.692 parsl.dataflow.strategy:125 [DEBUG]  Scaling strategy: None
2020-05-26 12:48:20.693 parsl.dataflow.dflow:484 [DEBUG]  Adding output dependencies
2020-05-26 12:48:20.693 parsl.dataflow.dflow:514 [DEBUG]  Not performing staging for: 'stress_ng_0'
2020-05-26 12:48:20.693 parsl.app.futures:56 [WARNING]  DataFuture constructed with a string, not a File. This is deprecated.
2020-05-26 12:48:20.693 parsl.app.futures:72 [DEBUG]  Creating DataFuture with parent: <AppFuture super=<AppFuture at 0x7f46c8a609b0 state=pending>> and file: <<class 'parsl.data_provider.files.File'> at 0x7f46c89e1b00 url=stress_ng_0 scheme=file netloc= path=stress_ng_0 filename=stress_ng_0>
2020-05-26 12:48:20.693 parsl.dataflow.dflow:708 [INFO]  Task 0 submitted for App stress_ng, waiting on tasks []
2020-05-26 12:48:20.694 parsl.dataflow.dflow:714 [DEBUG]  Task 0 set to pending state with AppFuture: <AppFuture super=<AppFuture at 0x7f46c8a609b0 state=pending>>
2020-05-26 12:48:20.694 parsl.executors.high_throughput.executor:537 [DEBUG]  Pushing function <function stress_ng at 0x7f46c8a5fc80> to queue with args (<function stress_ng at 0x7f46d3b201e0>,)
2020-05-26 12:48:20.695 parsl.dataflow.dflow:452 [INFO]  Task 0 launched on executor htex_Local
2020-05-26 12:48:20.695 parsl.dataflow.dflow:484 [DEBUG]  Adding output dependencies
2020-05-26 12:48:20.695 parsl.dataflow.dflow:514 [DEBUG]  Not performing staging for: 'stress_ng_1'
2020-05-26 12:48:20.695 parsl.app.futures:56 [WARNING]  DataFuture constructed with a string, not a File. This is deprecated.
2020-05-26 12:48:20.695 parsl.app.futures:72 [DEBUG]  Creating DataFuture with parent: <AppFuture super=<AppFuture at 0x7f46c89e1be0 state=pending>> and file: <<class 'parsl.data_provider.files.File'> at 0x7f46c89e1dd8 url=stress_ng_1 scheme=file netloc= path=stress_ng_1 filename=stress_ng_1>
2020-05-26 12:48:20.695 parsl.dataflow.dflow:708 [INFO]  Task 1 submitted for App stress_ng, waiting on tasks []
2020-05-26 12:48:20.695 parsl.dataflow.dflow:714 [DEBUG]  Task 1 set to pending state with AppFuture: <AppFuture super=<AppFuture at 0x7f46c89e1be0 state=pending>>
2020-05-26 12:48:20.695 parsl.executors.high_throughput.executor:537 [DEBUG]  Pushing function <function stress_ng at 0x7f46c8a6a620> to queue with args (<function stress_ng at 0x7f46d3b201e0>,)
2020-05-26 12:48:20.696 parsl.dataflow.dflow:452 [INFO]  Task 1 launched on executor htex_Local
2020-05-26 12:48:20.696 parsl.dataflow.dflow:484 [DEBUG]  Adding output dependencies
2020-05-26 12:48:20.696 parsl.dataflow.dflow:514 [DEBUG]  Not performing staging for: 'stress_ng_2'
2020-05-26 12:48:20.696 parsl.app.futures:56 [WARNING]  DataFuture constructed with a string, not a File. This is deprecated.
2020-05-26 12:48:20.696 parsl.app.futures:72 [DEBUG]  Creating DataFuture with parent: <AppFuture super=<AppFuture at 0x7f46c89e1e48 state=pending>> and file: <<class 'parsl.data_provider.files.File'> at 0x7f46c89f80b8 url=stress_ng_2 scheme=file netloc= path=stress_ng_2 filename=stress_ng_2>
2020-05-26 12:48:20.696 parsl.dataflow.dflow:708 [INFO]  Task 2 submitted for App stress_ng, waiting on tasks []
2020-05-26 12:48:20.696 parsl.dataflow.dflow:714 [DEBUG]  Task 2 set to pending state with AppFuture: <AppFuture super=<AppFuture at 0x7f46c89e1e48 state=pending>>
2020-05-26 12:48:20.696 parsl.executors.high_throughput.executor:537 [DEBUG]  Pushing function <function stress_ng at 0x7f46c8a4ed08> to queue with args (<function stress_ng at 0x7f46d3b201e0>,)
2020-05-26 12:48:20.696 parsl.dataflow.dflow:452 [INFO]  Task 2 launched on executor htex_Local
2020-05-26 12:48:41.297 parsl.dataflow.dflow:288 [INFO]  Task 1 completed
2020-05-26 12:48:41.297 parsl.dataflow.dflow:292 [INFO]  Standard output for task 1 available at stress_ng.stdout
2020-05-26 12:48:41.297 parsl.dataflow.dflow:294 [INFO]  Standard error for task 1 available at stress_ng.stderr
2020-05-26 12:48:41.297 parsl.dataflow.dflow:288 [INFO]  Task 2 completed
2020-05-26 12:48:41.297 parsl.dataflow.dflow:292 [INFO]  Standard output for task 2 available at stress_ng.stdout
2020-05-26 12:48:41.297 parsl.dataflow.dflow:294 [INFO]  Standard error for task 2 available at stress_ng.stderr
2020-05-26 12:48:41.298 parsl.dataflow.dflow:288 [INFO]  Task 0 completed
2020-05-26 12:48:41.298 parsl.dataflow.dflow:292 [INFO]  Standard output for task 0 available at stress_ng.stdout
2020-05-26 12:48:41.298 parsl.dataflow.dflow:294 [INFO]  Standard error for task 0 available at stress_ng.stderr
2020-05-26 12:48:41.299 parsl.dataflow.dflow:864 [INFO]  DFK cleanup initiated
2020-05-26 12:48:41.299 parsl.dataflow.dflow:750 [INFO]  Summary of tasks in DFK:
2020-05-26 12:48:41.299 parsl.dataflow.dflow:781 [INFO]  Tasks in state States.done: 0, 1, 2
2020-05-26 12:48:41.299 parsl.dataflow.dflow:788 [INFO]  End of summary
2020-05-26 12:48:41.299 parsl.dataflow.dflow:888 [INFO]  Terminating flow_control and strategy threads
2020-05-26 12:48:41.302 parsl.executors.high_throughput.executor:507 [DEBUG]  [HOLD_BLOCK]: Sending hold to manager: dfd2e5b9a8f4
2020-05-26 12:48:41.304 parsl.executors.high_throughput.executor:475 [DEBUG]  Sent hold request to worker: dfd2e5b9a8f4
2020-05-26 12:48:41.304 parsl.providers.local.local:233 [DEBUG]  Terminating job/proc_id: 9536
2020-05-26 12:48:41.304 parsl.executors.high_throughput.executor:634 [INFO]  Attempting HighThroughputExecutor shutdown
2020-05-26 12:48:41.305 parsl.executors.high_throughput.executor:638 [INFO]  Finished HighThroughputExecutor shutdown attempt
2020-05-26 12:48:41.305 parsl.executors.threads:96 [DEBUG]  Done with executor shutdown
2020-05-26 12:48:41.305 parsl.dataflow.dflow:920 [INFO]  DFK cleanup complete
